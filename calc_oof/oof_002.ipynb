{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0931e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import cv2\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os, sys, yaml\n",
    "\n",
    "sys.path.append('/workspace/siim-rsna-2021')\n",
    "from src.logger import setup_logger, LOGGER\n",
    "from src.meter import mAPMeter, AUCMeter, APMeter, AverageValueMeter\n",
    "from src.utils import plot_sample_images\n",
    "from src.segloss import SymmetricLovaszLoss\n",
    "\n",
    "\n",
    "# import neptune.new as neptune\n",
    "import wandb\n",
    "import pydicom\n",
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "\n",
    "target_columns = [\n",
    "    \"Negative for Pneumonia\", \"Typical Appearance\", \"Indeterminate Appearance\", \"Atypical Appearance\", \"is_none\"\n",
    "]\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff8bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.exp414.train import Net as Net414\n",
    "from exp.exp415.train import Net as Net415\n",
    "from exp.exp416.train import Net as Net416\n",
    "from exp.exp417.train import Net as Net417\n",
    "\n",
    "from exp.exp418.train import Net as Net418\n",
    "from exp.exp419.train import Net as Net419\n",
    "from exp.exp420.train import Net as Net420\n",
    "\n",
    "from exp.exp520.train import Net as Net520\n",
    "from exp.exp551.train import Net as Net551\n",
    "from exp.exp552.train import Net as Net552\n",
    "from exp.exp553.train import Net as Net553\n",
    "\n",
    "from exp.exp605.train import Net as Net605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e897c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 image_size=512,\n",
    "                 transform=None,\n",
    "                 ):\n",
    "        self.df = df\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.cols = target_columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        images = cv2.imread(row.npy_path)\n",
    "\n",
    "        # original image size\n",
    "        original_h = images.shape[0]\n",
    "        original_w = images.shape[1]\n",
    "        images = cv2.resize(images, (512, 512))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=images)\n",
    "            images_only = aug['image'].astype(np.float32).transpose(2, 0, 1) / 255\n",
    "        return {\n",
    "            \"image\": torch.tensor(images_only, dtype=torch.float),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf55255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_transforms(image_size=512):\n",
    "    return albumentations.Compose([\n",
    "        albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c5bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sub_list = [\n",
    "\n",
    "#     # prediction set, b6 mask\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net414(\"tf_efficientnetv2_m_in21k\"),\n",
    "#         \"tf_efficientnetv2_m_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp414/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp414/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp414/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp414/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp414/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp414\"\n",
    "#     ],\n",
    "    \n",
    "#     # prediction set, b6 mask\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net415(\"tf_efficientnetv2_m_in21k\"),\n",
    "#         \"tf_efficientnetv2_m_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp415/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp415/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp415/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp415/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp415/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp415\"\n",
    "#     ],\n",
    "\n",
    "#     # prediction set, b7 mask\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net416(\"tf_efficientnetv2_m_in21k\"),\n",
    "#         \"tf_efficientnetv2_m_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp416/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp416/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp416/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp416/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp416/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp416\"\n",
    "#     ],\n",
    "    \n",
    "#     # prediction set, b6 mask\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net417(\"tf_efficientnetv2_m_in21k\"),\n",
    "#         \"tf_efficientnetv2_m_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp417/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp417/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp417/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp417/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp417/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp417\"\n",
    "#     ],\n",
    "\n",
    "    # ===========================================\n",
    "    # Eff v2 L\n",
    "    # ===========================================\n",
    "\n",
    "\n",
    "#     # prediction set, b7 map\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net419(\"tf_efficientnetv2_l_in21k\"),\n",
    "#         \"tf_efficientnetv2_l_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp419/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp419/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp419/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp419/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp419/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp419\"\n",
    "#     ],\n",
    "\n",
    "#     # prediction set, b6, b7\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net420(\"tf_efficientnetv2_l_in21k\"),\n",
    "#         \"tf_efficientnetv2_l_in21k\",\n",
    "#         # img_size\n",
    "#         512,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp420/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp420/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp420/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp420/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp420/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp420\"\n",
    "#     ],\n",
    "\n",
    "    # prediction set, b6, b7\n",
    "    [\n",
    "        # backbone\n",
    "        Net420(\"tf_efficientnetv2_l_in21k\"),\n",
    "        \"tf_efficientnetv2_l_in21k\",\n",
    "        # img_size\n",
    "        512,\n",
    "        # weight list\n",
    "        [\n",
    "            \"/workspace/output/exp520/model/cv0_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv1_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv2_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv3_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv4_weight_checkpoint_best.pth\",\n",
    "        ],\n",
    "        \"exp520\"\n",
    "    ],\n",
    "    \n",
    "    # prediction set, b6, b7\n",
    "    [\n",
    "        # backbone\n",
    "        Net420(\"tf_efficientnetv2_l_in21k\"),\n",
    "        \"tf_efficientnetv2_l_in21k\",\n",
    "        # img_size\n",
    "        640,\n",
    "        # weight list\n",
    "        [\n",
    "            \"/workspace/output/exp520/model/cv0_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv1_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv2_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv3_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp520/model/cv4_weight_checkpoint_best.pth\",\n",
    "        ],\n",
    "        \"exp520_640\"\n",
    "    ],\n",
    "    \n",
    "    # prediction set, b6\n",
    "    [\n",
    "        # backbone\n",
    "        Net418(\"tf_efficientnetv2_l_in21k\"),\n",
    "        \"tf_efficientnetv2_l_in21k\",\n",
    "        # img_size\n",
    "        640,\n",
    "        # weight list\n",
    "        [\n",
    "            \"/workspace/output/exp551/model/cv0_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp551/model/cv1_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp551/model/cv2_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp551/model/cv3_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp551/model/cv4_weight_checkpoint_best.pth\",\n",
    "        ],\n",
    "        \"exp551_640\"\n",
    "    ],\n",
    "    \n",
    "    # prediction set, b6\n",
    "    [\n",
    "        # backbone\n",
    "        Net552(\"tf_efficientnetv2_l_in21k\"),\n",
    "        \"tf_efficientnetv2_l_in21k\",\n",
    "        # img_size\n",
    "        640,\n",
    "        # weight list\n",
    "        [\n",
    "            \"/workspace/output/exp552/model/cv0_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp552/model/cv1_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp552/model/cv2_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp552/model/cv3_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp552/model/cv4_weight_checkpoint_best.pth\",\n",
    "        ],\n",
    "        \"exp552_640\"\n",
    "    ],\n",
    "    \n",
    "    # prediction set, b6\n",
    "    [\n",
    "        # backbone\n",
    "        Net553(\"tf_efficientnetv2_l_in21k\"),\n",
    "        \"tf_efficientnetv2_l_in21k\",\n",
    "        # img_size\n",
    "        640,\n",
    "        # weight list\n",
    "        [\n",
    "            \"/workspace/output/exp553/model/cv0_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp553/model/cv1_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp553/model/cv2_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp553/model/cv3_weight_checkpoint_best.pth\",\n",
    "            \"/workspace/output/exp553/model/cv4_weight_checkpoint_best.pth\",\n",
    "        ],\n",
    "        \"exp553_640\"\n",
    "    ],\n",
    "\n",
    "    # ===========================================\n",
    "    # Swin transformer\n",
    "    # ===========================================\n",
    "\n",
    "#     # prediction set\n",
    "#     [\n",
    "#         # backbone\n",
    "#         Net605(\"swin_base_patch4_window12_384\"),\n",
    "#         \"swin_base_patch4_window12_384\",\n",
    "#         # img_size\n",
    "#         384,\n",
    "#         # weight list\n",
    "#         [\n",
    "#             \"/workspace/output/exp605/model/cv0_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp605/model/cv1_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp605/model/cv2_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp605/model/cv3_weight_checkpoint_best.pth\",\n",
    "#             \"/workspace/output/exp605/model/cv4_weight_checkpoint_best.pth\",\n",
    "#         ],\n",
    "#         \"exp605\"\n",
    "#     ],\n",
    "    \n",
    "    \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557a7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0a855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef4f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"/workspace/data/df_train_study_level_npy640_3_w_bbox.csv\")\n",
    "df = df_original.groupby('image_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3710d352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:55, 115.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1223, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [03:47, 114.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1220, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [05:43, 115.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1221, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [07:41, 115.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1228, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [09:40, 116.01s/it]\u001b[A\n",
      " 20%|██        | 1/5 [09:40<38:40, 580.03s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1225, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:14, 134.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1223, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [04:31, 135.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1220, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [06:41, 133.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1221, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [08:52, 132.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1228, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [11:08, 133.67s/it]\u001b[A\n",
      " 40%|████      | 2/5 [20:48<30:19, 606.52s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1225, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:08, 128.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1223, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [04:14, 127.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1220, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [06:22, 127.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1221, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [08:34, 128.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1228, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [10:49, 129.83s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [31:37<20:38, 619.30s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1225, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:09, 129.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1223, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [04:17, 129.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1220, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [06:25, 128.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1221, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [08:38, 129.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1228, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [10:50, 130.12s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [42:28<10:28, 628.70s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1225, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:10, 130.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1223, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [04:17, 129.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1220, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [06:28, 129.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1221, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [08:39, 129.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1228, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [10:48, 129.70s/it]\u001b[A\n",
      "100%|██████████| 5/5 [53:16<00:00, 639.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds.shape: (1225, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# key: image size, value: model\n",
    "model_dict = {}\n",
    "\n",
    "image_size_list = []\n",
    "\n",
    "for model_set in tqdm(study_sub_list):\n",
    "    # 画像サイズをkey, modelのリストをvalueにする\n",
    "    # keyがまだない場合はからのリストを登録\n",
    "    model_dict.setdefault(model_set[2], [])\n",
    "    model_list = []\n",
    "    exp_name = model_set[-1]\n",
    "    for cv, ckpt in tqdm(enumerate(model_set[3])):\n",
    "        model = model_set[0].to(device)\n",
    "        weight = torch.load(ckpt, map_location=device)\n",
    "        model.load_state_dict(weight[\"state_dict\"])\n",
    "        model.eval()\n",
    "        \n",
    "        df_val = df[df.cv == cv].reset_index(drop=True)\n",
    "        \n",
    "        dataset = CustomDataset(df=df_val, transform=get_val_transforms(model_set[2]))\n",
    "        test_loader = DataLoader(\n",
    "            dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=32,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        pred_list1 = []\n",
    "        for i, image in enumerate(test_loader):\n",
    "            pred_list2 = []\n",
    "            pred_mask2 = []\n",
    "            image = image[\"image\"].to(device)\n",
    "            with torch.no_grad():\n",
    "                preds, *_ = model(image)\n",
    "                preds = preds.cpu().detach().sigmoid()\n",
    "\n",
    "                # average prediction\n",
    "                pred_list1.append(preds)\n",
    "\n",
    "        preds = torch.cat(pred_list1).numpy()\n",
    "        print(f\"preds.shape: {preds.shape}\")\n",
    "        np.save(f'/workspace/output/oof/{exp_name}_cv{cv}.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c38e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6313b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1b2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c052db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603a359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b1286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdc151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c485f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
